{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db380cb",
   "metadata": {},
   "source": [
    "#### Install Pypop\n",
    "https://github.com/alexlancaster/pypop?tab=readme-ov-file#readme\n",
    "\n",
    "#### Install Arlequin\n",
    "http://cmpg.unibe.ch/software/arlequin3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c6690",
   "metadata": {},
   "source": [
    "## ARLEQUIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input preparation for the HW, LD and haplotypic frequency estimation in the Arlequin Software\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "txt_file example\n",
    "id    A        A       B      B        C       C      DRB1    DRB1   DQB1    DQB1    DPB1    DPB1\n",
    "1   24:02   24:02   49:01   51:01   06:02   15:02   04:03   14:54   03:02   05:03   04:01   04:01\n",
    "2   24:02   68:01   18:01   35:03   04:01   07:01   11:04   12:01   03:01   03:01   02:01   04:02\n",
    "3   02:01   11:01   44:05   51:01   02:02   15:02   16:01   16:01   05:02   05:02   04:02   10:01\n",
    "4   02:17   32:01   15:01   51:01   03:04   15:02   01:01   14:54   05:01   05:03   04:01   104:01\n",
    "5   02:01   24:02   18:01   35:03   04:01   12:03   11:04   11:04   03:01   03:01   04:01   14:01\n",
    "6   02:01   11:01   15:01   39:01   04:01   12:03   12:01   16:01   03:01   05:02   04:01   15:01\n",
    "7   01:01   23:01   07:05   49:01   07:01   15:05   07:01   11:01   02:02   03:01   02:01   04:01\n",
    "8   02:01   11:01   35:01   51:01   04:01   15:02   01:01   13:01   05:01   06:03   02:01   03:01\n",
    "'''\n",
    "\n",
    "def arlequin_inputs(txt_file, #txt file\n",
    "                    hla_gene=None, #A or B or C...\n",
    "                    all_genes=None, #A,B,C,DRB1,DQB1,DPB1\n",
    "                    include_missing_data=None, #TRUE: if you have missing data\n",
    "                    num_of_genes=None, #num_of_genes\n",
    "                    HW=None, #=1 if you want an arlequin input file for Hardy-Weinberg equilibrium\n",
    "                    LD=None, #=1 if you want an arlequin input file for Linkage Disequillibrium\n",
    "                    HF=None, #=1 if you want an arlequin input file for Haplotypic Frequencies\n",
    "                    path=None #just the path of the txt file\n",
    "                   ):    \n",
    "    '''\n",
    "    txt_file should contain the genotypes with unknown phasing in any resolution of \n",
    "    the HLA genes A, B, C, DRB1, DQB1, DPB1 in this order only.\n",
    "    If there are not data about some of these genes, just put None values on the respective columns.\n",
    "    In this case set include_missing_data=True.\n",
    "    \n",
    "    Your 'path' directory should contain 3 subdirectories: HW/, LD/ and HF/.\n",
    "    '''\n",
    "    \n",
    "    if include_missing_data and txt_file == 'mylopotamos.txt':\n",
    "        raise Exception('This file has no missing data.')\n",
    " \n",
    "    if hla_gene and all_genes or hla_gene and num_of_genes or num_of_genes and not all_genes:\n",
    "        raise Exception('You can pick only 1 gene, or all of them, or the first n of them.')\n",
    "    \n",
    "    if num_of_genes and not 1<num_of_genes<6 and not isinstance(num_of_genes, int):\n",
    "        raise Exception(\"num_of_genes should be an integer from 2 to 5 indicating the first n genes that you wish to be in the input for Arlequin\")\n",
    "    \n",
    "    if hla_gene and HF or hla_gene and LD:\n",
    "        raise Exception('You cannot create haplotypes or calculate Linkage Disequillibrium with just 1 genetic loci.')\n",
    "    \n",
    "    if HW and LD or HW and HF or LD and HF:\n",
    "        raise Exception('You can choose only 1 type of analysis for the input preparation.')\n",
    "    \n",
    "    with open(txt_file, 'r') as pop:\n",
    "        pop = pop.readlines()\n",
    "\n",
    "    pop = [x.strip('\\n').split('\\t') for x in pop]\n",
    "    \n",
    "    if HF:\n",
    "        pop = [[x.replace(' ','') for x in y] for y in pop]\n",
    "    else:\n",
    "        pop = [[x.replace(' ','').replace(':','') for x in y] for y in pop]\n",
    "    \n",
    "    if not include_missing_data:\n",
    "        pop_tmp = [x for x in pop if sum('' == s for s in x)==0]\n",
    "    else:\n",
    "        pop_tmp = pop.copy()\n",
    "    \n",
    "    if all_genes:\n",
    "        \n",
    "        pop = [['A'+x[1],'A'+x[2],'B'+x[3],'B'+x[4],'C'+x[5],'C'+x[6],'DR'+x[7],'DR'+x[8],'DQ'+x[9],'DQ'+x[10],'DP'+x[11],'DP'+x[12]] for x in pop_tmp[1:]]\n",
    "        \n",
    "        if num_of_genes:\n",
    "            pop = [x[:2*num_of_genes] for x in pop]\n",
    "        \n",
    "        obs_counts_pop_A = dict(Counter(map(tuple, pop))) \n",
    "        obs_counts_pop_A = {k:v for k,v in sorted(obs_counts_pop_A.items(), key = lambda item:item[1], reverse=True)}\n",
    "        \n",
    "        if num_of_genes:\n",
    "            \n",
    "            if num_of_genes == 2:\n",
    "                input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\t'+k[2]+'\\n'+'\\t\\t'+k[1]+'\\t'+k[3]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "\n",
    "            if num_of_genes == 3:\n",
    "                input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\t'+k[2]+'\\t'+k[4]+'\\n'+'\\t\\t'+k[1]+'\\t'+k[3]+'\\t'+k[5]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "\n",
    "            if num_of_genes == 4:\n",
    "                input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\t'+k[2]+'\\t'+k[4]+'\\t'+k[6]+'\\n'+'\\t\\t'+k[1]+'\\t'+k[3]+'\\t'+k[5]+'\\t'+k[7]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "\n",
    "            if num_of_genes == 5:\n",
    "                input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\t'+k[2]+'\\t'+k[4]+'\\t'+k[6]+'\\t'+k[8]+'\\n'+'\\t\\t'+k[1]+'\\t'+k[3]+'\\t'+k[5]+'\\t'+k[7]+'\\t'+k[9]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\t'+k[2]+'\\t'+k[4]+'\\t'+k[6]+'\\t'+k[8]+'\\t'+k[10]+'\\n'+'\\t\\t'+k[1]+'\\t'+k[3]+'\\t'+k[5]+'\\t'+k[7]+'\\t'+k[9]+'\\t'+k[11]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "            \n",
    "        input_tmp = [str(input_tmp.index(x)+1)+x for x in input_tmp ]\n",
    "        \n",
    "        if include_missing_data:\n",
    "            input_tmp = [x.replace('\\tA\\n', '\\t?\\n').replace('\\tB\\n', '\\t?\\n').replace('\\tC\\n', '\\t?\\n').replace('\\tDR\\n', '\\t?\\n').replace('\\tDQ\\n', '\\t?\\n').replace('\\tDP\\n', '\\t?\\n').replace('\\tA\\t', '\\t?\\t').replace('\\tB\\t', '\\t?\\t').replace('\\tC\\t', '\\t?\\t').replace('\\tDR\\t', '\\t?\\t').replace('\\tDQ\\t', '\\t?\\t') for x in input_tmp]       \n",
    "        \n",
    "        to_write = ''.join(input_tmp)\n",
    "        \n",
    "        \n",
    "    if not all_genes:\n",
    "        \n",
    "        if hla_gene in ('DRB1','DQB1','DPB1'):\n",
    "            pop = [[hla_gene[0:2]+x.replace(':','') for x in y] for y in pop_tmp]\n",
    "        else:\n",
    "            pop = [[hla_gene+x.replace(':','') for x in y] for y in pop_tmp]\n",
    "\n",
    "        if hla_gene == 'A':\n",
    "            pop = [x[1:3] for x in pop[1:]]\n",
    "        elif hla_gene == 'B':\n",
    "            pop = [x[3:5] for x in pop[1:]]\n",
    "        elif hla_gene == 'C':\n",
    "            pop = [x[5:7] for x in pop[1:]]\n",
    "        elif hla_gene == 'DRB1':\n",
    "            pop = [x[7:9] for x in pop[1:]]\n",
    "        elif hla_gene == 'DQB1':\n",
    "            pop = [x[9:11] for x in pop[1:]]\n",
    "        elif hla_gene == 'DPB1':\n",
    "            pop = [x[11:] for x in pop[1:]] \n",
    "\n",
    "        pop = sorted(pop, key = lambda x:(x[0],x[1]))\n",
    "\n",
    "        obs_counts_pop_A = dict(Counter(map(tuple, pop))) \n",
    "\n",
    "        input_tmp = ['\\t'+str(v)+'\\t'+k[0]+'\\n'+'\\t\\t'+k[1]+'\\n' for k,v in obs_counts_pop_A.items()]\n",
    "\n",
    "        input_tmp = [str(input_tmp.index(x)+1)+x for x in input_tmp ]\n",
    "           \n",
    "        if include_missing_data:\n",
    "            input_tmp = [x.replace('\\tA\\n', '\\t?\\n').replace('\\tB\\n', '\\t?\\n').replace('\\tC\\n', '\\t?\\n').replace('\\tDR\\n', '\\t?\\n').replace('\\tDQ\\n', '\\t?\\n').replace('\\tDP\\n', '\\t?\\n') for x in input_tmp]       \n",
    "        \n",
    "        to_write = ''.join(input_tmp)  \n",
    "\n",
    "    \n",
    "    place = txt_file.split('.')[0]\n",
    "        \n",
    "    if HW:\n",
    "        path = path + 'HW/'\n",
    "    elif LD:\n",
    "        path = path + 'LD/'\n",
    "    elif HF:\n",
    "        path = path + 'HF/'\n",
    "    else:\n",
    "        raise Exception('Something went wrong. Check the HW, LD and HF parameters.')\n",
    "    \n",
    "    n1 ='{'\n",
    "    n2='}'\n",
    "    \n",
    "    if all_genes:\n",
    "        if not num_of_genes:\n",
    "            n = 6\n",
    "        else:\n",
    "            n = num_of_genes\n",
    "    \n",
    "    if HW:\n",
    "        title = f'Hardy-Weinberg equilibrium exact test for {len(pop)} individuals from {place}'\n",
    "    elif LD:\n",
    "        title = f'Linkage Disequillibrium test for {n} loci of {len(pop)} individuals from {place}'\n",
    "    elif HF:\n",
    "        title = f'Haplotypic Frequencies estimation for {n} loci of {len(pop)} individuals from {place}'\n",
    "    else:\n",
    "        raise Exception('Something went wrong. Check the HW, LD and HF parameters.')\n",
    "    \n",
    "    final_input = f'''[Profile]\n",
    "\n",
    "     Title=\"{title}\"\n",
    "     NbSamples=1\n",
    "     DataType=STANDARD\n",
    "     GenotypicData=1\n",
    "     LocusSeparator=TAB\n",
    "     GameticPhase=0\n",
    "     RecessiveData=0\n",
    "     MissingData=\"?\"\n",
    "\n",
    "[Data] \n",
    "\n",
    "[[Samples]] \n",
    "\n",
    "    SampleName=\"{len(pop)} from {place}\"\n",
    "    SampleSize={len(pop)} # Number of diploid individuals in sample \n",
    "    SampleData= {n1}\n",
    "\n",
    "{to_write}{n2}'''\n",
    "    \n",
    "    if include_missing_data:\n",
    "        md = '_missing_data'\n",
    "    else:\n",
    "        md = ''\n",
    "    \n",
    "    if all_genes:\n",
    "        \n",
    "        if HW:\n",
    "            \n",
    "            if not num_of_genes:\n",
    "                if os.path.exists(f'{path}{place}_Arlequin_HW_all{md}.arp'):\n",
    "                    os.remove(f'{path}{place}_Arlequin_HW_all{md}.arp')\n",
    "                    \n",
    "                with open(f'{path}{place}_Arlequin_HW_all{md}.arp', 'w') as h:\n",
    "                    h.write(final_input)\n",
    "            else:\n",
    "                \n",
    "                if os.path.exists(f'{path}{place}_Arlequin_HW_{n}{md}.arp'):\n",
    "                    os.remove(f'{path}{place}_Arlequin_HW_{n}{md}.arp')\n",
    "\n",
    "                with open(f'{path}{place}_Arlequin_HW_{n}{md}.arp', 'w') as h:\n",
    "                    h.write(final_input)\n",
    "                    \n",
    "        if LD:\n",
    "            \n",
    "            if not num_of_genes:\n",
    "                if os.path.exists(f'{path}{place}_Arlequin_LD_all{md}.arp'):\n",
    "                    os.remove(f'{path}{place}_Arlequin_LD_all{md}.arp')\n",
    "\n",
    "                with open(f'{path}{place}_Arlequin_LD_all{md}.arp', 'w') as h:\n",
    "                    h.write(final_input)\n",
    "            else:\n",
    "                \n",
    "                if os.path.exists(f'{path}{place}_Arlequin_LD_{n}{md}.arp'):\n",
    "                    os.remove(f'{path}{place}_Arlequin_LD_{n}{md}.arp')\n",
    "\n",
    "                with open(f'{path}{place}_Arlequin_LD_{n}{md}.arp', 'w') as h:\n",
    "                    h.write(final_input)\n",
    "                    \n",
    "        if HF:\n",
    "            \n",
    "            if os.path.exists(f'{path}{place}_Arlequin_HF_{n}{md}.arp'):\n",
    "                os.remove(f'{path}{place}_Arlequin_HF_{n}{md}.arp')\n",
    "\n",
    "            with open(f'{path}{place}_Arlequin_HF_{n}{md}.arp', 'w') as h:\n",
    "                h.write(final_input)\n",
    "                    \n",
    "    if not all_genes:        \n",
    "        \n",
    "        if HW:\n",
    "            \n",
    "            if os.path.exists(f'{path}{place}_Arlequin_HW_{hla_gene}{md}.arp'):\n",
    "                os.remove(f'{path}{place}_Arlequin_HW_{hla_gene}{md}.arp')\n",
    "\n",
    "            with open(f'{path}{place}_Arlequin_HW_{hla_gene}{md}.arp', 'w') as h:\n",
    "                h.write(final_input)\n",
    "                \n",
    "        if LD or HF:\n",
    "            raise Exception('Something went wrong with the analysis and the number of the genes.')\n",
    "\n",
    "# arlequin_inputs('Crete_75.txt', hla_gene=None, all_genes=True, include_missing_data=False, num_of_genes=None, HW=True, LD=None, HF=None, path = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function merges multiple .arp files (Arlequin v.3.5.2.2 format) for the SAME analysis, \n",
    "so be careful when choosing the inputs. \n",
    "'''\n",
    "def merge_arps(list_with_arps, path, remove_inputs=None):\n",
    "    \n",
    "    if len(list_with_arps) < 2:\n",
    "        raise Exception('The list should contain at least 2 .arp files for merging.')\n",
    "    \n",
    "    os.chdir(path)\n",
    "        \n",
    "    for x in range(len(list_with_arps)):\n",
    "        if not os.path.exists(list_with_arps[x]):\n",
    "            raise Exception(f'The file {list_with_arps[x]} does not exist. Choose it from the correct folder.')\n",
    "        \n",
    "    pop_num = len(list_with_arps)\n",
    "    \n",
    "    to_write_list = []\n",
    "    \n",
    "    for x in range(len(list_with_arps)):\n",
    "        with open(list_with_arps[x], 'r') as tmp:\n",
    "            tmp = tmp.readlines()\n",
    "            \n",
    "        tmp = [x.strip('\\n') for x in tmp]    \n",
    "        tmp = [tmp[x+1:] for x in range(len(tmp)) if '[[Samples]]' in tmp[x]]        \n",
    "        \n",
    "        to_write_list.append(tmp[0])\n",
    "\n",
    "    header = [[f'''[Profile]\n",
    "\n",
    "     Title=\"Genotypes of all populations together\"\n",
    "     NbSamples={pop_num}\n",
    "     DataType=STANDARD\n",
    "     GenotypicData=1\n",
    "     LocusSeparator=TAB\n",
    "     GameticPhase=0\n",
    "     RecessiveData=0\n",
    "     MissingData=\"?\"\n",
    "\n",
    "[Data] \n",
    "\n",
    "[[Samples]]''']]\n",
    "    \n",
    "    final_output = header + to_write_list\n",
    "    \n",
    "    if os.path.exists(f'{path}merged.arp'):\n",
    "        os.remove(f'{path}merged.arp')\n",
    "\n",
    "    with open(f'{path}merged.arp', 'w') as h:\n",
    "        for _list in final_output:\n",
    "            for _string in _list:\n",
    "                h.write(str(_string) + '\\n')   \n",
    "                \n",
    "    if remove_inputs:\n",
    "        for x in range(len(list_with_arps)):\n",
    "            if os.path.exists(list_with_arps[x]):\n",
    "                os.remove(list_with_arps[x])\n",
    "# merge_arps(['/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/Chania.arp', '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/Rethymno.arp', '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/Heraklion.arp', '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/Lasithi.arp'], path = '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "'''\n",
    "The order of the populations should be Mylopotamos, rest, Crete and the analysis\n",
    "should contain 6 HLA genes with the order A, B, C, DRB1, DQB1, DPB1.\n",
    "\n",
    "The p-values and the haplotypic frequencies cannot be obtained from .xml files \n",
    "that have come from different types of analyses, or from different .ars files \n",
    "or from different parameters in the .arp files or from different types of inputs in \n",
    "general than the ones we used. Our data were genotype data with unknown phasing.\n",
    "\n",
    "The .xml file must contain only once in its name the expression \n",
    "_{analysis}_{number_of_loci}_ , where {analysis} can either be 'HF','HW' or 'LD'\n",
    "and {number_of_loci} can either be 2,3,4,5 or 6. Examples of this  expression: \n",
    "_HF_6_ , _LD_5_ , _HF_4_ .\n",
    "'''\n",
    "\n",
    "def obtain_pvalue_from_Arlequin_xml(xml_file, analysis):    \n",
    "    if not os.path.exists(xml_file):\n",
    "        raise Exception('This file does not exist. Chose the correct one from the correct folder.')\n",
    "    \n",
    "    if analysis not in ('HW', 'LD', 'HF'):\n",
    "        raise Exception(\"analysis can only be 'HW', 'LD' or 'HF'\")\n",
    "    \n",
    "    if xml_file.split(f'{analysis}_')[1][0] == 'a':\n",
    "        n = 6\n",
    "    else:\n",
    "        n = int(xml_file.split(f'{analysis}_')[1][0])\n",
    "    \n",
    "    with open(xml_file, 'r') as h:\n",
    "        h = h.readlines()\n",
    "        \n",
    "    h = [x.strip('\\n') for x in h]              \n",
    "        \n",
    "    if analysis == 'HF': \n",
    "        \n",
    "        start = [i for i, x in enumerate(h) if x ==  '    #   Haplotype     Freq.      s.d.']\n",
    "        end = [i for i, x in enumerate(h) if 'Sum of all' in x]\n",
    "        \n",
    "        if len(start) != len(end):\n",
    "            raise Exception('Something went wrong while parsing the HF.xml file. Could not retrieve the frequencies. Check the .xml file if there is something unusual happening between the populations.')\n",
    "        \n",
    "        haplotypes = [h[start[x]+3:end[x]-2] for x in range(len(start))]\n",
    "        haplotypes = [[y.strip(' ').split(' ') for y in x] for x in haplotypes]\n",
    "        haplotypes = [[z.split('\\t') for y in x for z in y if z] for x in haplotypes]\n",
    "        \n",
    "        haplotypes_tmp = []\n",
    "        \n",
    "        for x in range(len(haplotypes)):\n",
    "            haplotypes_tmp.append(list(itertools.chain.from_iterable(haplotypes[x])))\n",
    "        \n",
    "        haplotypes = [[haplotypes_tmp[x][y:y+n] for y in list(range(4,len(haplotypes_tmp[x]),n+5))] for x in range(len(haplotypes_tmp))]\n",
    "        \n",
    "        hfs = [[haplotypes_tmp[x][y-2] for y in list(range(4,len(haplotypes_tmp[x]),n+5))]  for x in range(len(haplotypes_tmp))]  \n",
    "         \n",
    "        for x in range(len(haplotypes)):\n",
    "            for y in range(len(haplotypes[x])):\n",
    "                haplotypes[x][y].append(hfs[x][y])\n",
    "       \n",
    "        haplotypes = [[['~'.join(haplotypes[x][y][0:n]).replace('A','A*').replace('B','B*').replace('C','C*').replace('DR','DRB1*').replace('DQ','DQB1*').replace('DP','DPB1*'),haplotypes[x][y][n]] for y in list(range(len(haplotypes[x])))] for x in range(len(haplotypes))]\n",
    "        \n",
    "        hf_list = []\n",
    "        \n",
    "        for x in range(len(haplotypes)):\n",
    "            hf_dict = {}\n",
    "            \n",
    "            for y in list(range(len(haplotypes[x]))):                \n",
    "                hf_dict[haplotypes[x][y][0]]=float(haplotypes[x][y][1])             \n",
    "            \n",
    "            hf_dict = {k: v for k, v in sorted(hf_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "            hf_list.append(hf_dict.copy())\n",
    "        \n",
    "        return hf_list\n",
    "    \n",
    "    elif analysis == 'LD':\n",
    "        \n",
    "        combos = len(list(itertools.combinations(list(range(n)), 2)))\n",
    "         \n",
    "        pop_num = len([h[x] for x in range(len(h)) if 'Test of linkage disequilibrium for all pairs of loci:' == h[x] ])\n",
    "        \n",
    "        h = [h[x+8:x+8+3*combos] for x in range(len(h)) if 'Test of linkage disequilibrium for all pairs of loci:' == h[x]]\n",
    "        ### the 3 in 3*combos stands for the number of lines in the .xml output LD file and not in the pop_num\n",
    "        \n",
    "        ld_pvals = [[h[x][y],float(re.findall(r'\\(P = .*?,', h[x][y+2])[0].split('=  ')[1].strip(','))] for y in list(range(0,3*combos,3)) for x in range(len(h))]\n",
    "        \n",
    "        pops_pvals = []\n",
    "        \n",
    "        for x in list(range(pop_num)):\n",
    "            tmp = []\n",
    "            \n",
    "            for y in range(x,len(ld_pvals),pop_num):\n",
    "                tmp.append(ld_pvals[y][1])\n",
    "            \n",
    "            pops_pvals.append(tmp)     \n",
    "        \n",
    "        return pops_pvals\n",
    "    \n",
    "    elif analysis == 'HW':\n",
    "        \n",
    "        pop_num = len([h[x] for x in range(len(h)) if \"Locus  #Genot       Obs.Het.     Exp.Het.   P-value     s.d.  Steps done\" == h[x] ])\n",
    "        \n",
    "        h = [h[x+2:x+2+n] for x in range(len(h)) if \"Locus  #Genot       Obs.Het.     Exp.Het.   P-value     s.d.  Steps done\" == h[x]]\n",
    "        h = [[x.strip(' ').split(' ') for x in y] for y in h]\n",
    "        h = [[z for y in x for z in y if z] for x in h]\n",
    "\n",
    "        pvals = [float(h[x][y]) for y in list(range(4, 4+7*(n-1)+1, 7)) for x in range(len(h))]\n",
    "        \n",
    "        pops_pvals = []\n",
    "        \n",
    "        for x in list(range(pop_num)):\n",
    "            tmp = []\n",
    "            \n",
    "            for y in range(x,len(pvals),pop_num):\n",
    "                tmp.append(pvals[y])\n",
    "            \n",
    "            pops_pvals.append(tmp)     \n",
    "        \n",
    "        return pops_pvals\n",
    "    \n",
    "DKMS_HW_path = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/HW/Crete_75_Arlequin_HW_all.res/'\n",
    "DKMS_LD_path = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/LD/Crete_75_Arlequin_LD_all.res/'\n",
    "DKMS_HF_path_6 = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/HF/Crete_75_Arlequin_HF_6.res/'\n",
    "\n",
    "# arlequin_DKMS_HW = obtain_pvalue_from_Arlequin_xml(f'{DKMS_HW_path}Crete_75_Arlequin_HW_all.xml', 'HW')\n",
    "# arlequin_DKMS_LD = obtain_pvalue_from_Arlequin_xml(f'{DKMS_LD_path}Crete_75_Arlequin_LD_all.xml', 'LD')\n",
    "# arlequin_DKMS_HF = obtain_pvalue_from_Arlequin_xml(f'{DKMS_HF_path_6}Crete_75_Arlequin_HF_6.xml','HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609871b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Arlequin 1000 times and get the mean of HWE p-values of Crete\n",
    "\n",
    "a = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/HW/'\n",
    "b = '../../../../arlecore_linux/arlecore3522_64bit HWequil.ars Crete_75_Arlequin_HW_all.arp'\n",
    "c = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/HW/Crete_75_Arlequin_HW_all.res/'\n",
    "d = 'mv Crete_75_Arlequin_HW_all.xml Crete_75_Arlequin_HW_6.xml'\n",
    "e = '/home/manos/Programs/Arlequin/cretan_HLA/DKMS/1835/HW/Crete_75_Arlequin_HW_all.res/Crete_75_Arlequin_HW_6.xml'\n",
    "\n",
    "def run_Arlequin_HWE(runs):\n",
    "        \n",
    "    pvals = []\n",
    "    \n",
    "    for run in range(runs):\n",
    "        print(run)\n",
    "        os.chdir(a)\n",
    "        os.system(b)\n",
    "        os.chdir(c)\n",
    "        os.system(d)\n",
    "        \n",
    "        tmp_pvals = obtain_pvalue_from_Arlequin_xml(e, 'HW')\n",
    "        pvals.append(tmp_pvals[0])\n",
    "        \n",
    "    os.chdir('/home/manos/Desktop/Manos/MSc-Bioinformatics/Thesis/scripts/Cretan_project/')\n",
    "    \n",
    "    return pvals\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):    \n",
    "    \n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "arlequin_DKMS_HW = run_Arlequin_HWE(1000)\n",
    "\n",
    "m_Crete_A, ci1_Crete_A, ci2_Crete_A = mean_confidence_interval([x[0] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "m_Crete_B, ci1_Crete_B, ci2_Crete_B = mean_confidence_interval([x[1] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "m_Crete_C, ci1_Crete_C, ci2_Crete_C = mean_confidence_interval([x[2] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "m_Crete_DRB1, ci1_Crete_DRB1, ci2_Crete_DRB1 = mean_confidence_interval([x[3] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "m_Crete_DQB1, ci1_Crete_DQB1, ci2_Crete_DQB1 = mean_confidence_interval([x[4] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "m_Crete_DPB1, ci1_Crete_DPB1, ci2_Crete_DPB1 = mean_confidence_interval([x[5] for x in arlequin_DKMS_HW], confidence=0.95)\n",
    "\n",
    "Crete_HW = [m_Crete_A,m_Crete_B,m_Crete_C,m_Crete_DRB1,m_Crete_DQB1,m_Crete_DPB1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arlequin_HWE_pvalues(arlequin_DKMS,log10=None):\n",
    "    \n",
    "    if log10:\n",
    "        \n",
    "        # We are adding 0.0001 on 0.0 p-values, because log tranformation is not posssible        \n",
    "        arlequin_DKMS = [-np.log10(x) for x in [0.0001 if x==0 else x for x in arlequin_DKMS]]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plt.scatter(list(range(1,31,5)), arlequin_DKMS, marker='*', color = 'blue',label=f'{n_cretans} Cretans',s=35)\n",
    "    \n",
    "    if log10:\n",
    "        plt.plot([0.8, 28.2],[-np.log10(0.05/6), -np.log10(0.05/6)], color ='red', label='a = -log10(0.05/6)')\n",
    "        ax.legend()\n",
    "#         ax.legend(loc='upper left')\n",
    "        plt.ylabel('-log10 transformed p-values', fontsize = 13)\n",
    "    else:\n",
    "        plt.plot([0.8, 28.2],[0.05/6, 0.05/6], color ='red', label='a = 0.05/6')\n",
    "    ### Corrected threshold: a / (number of genetic loci) where a == 0.05 and (number of genetic loci) == 6\n",
    "        ax.legend(loc='upper right')\n",
    "        plt.ylabel('p-values', fontsize = 15)\n",
    "    \n",
    "    plt.xticks(list(range(1,31,5)), ['A', 'B', 'C', 'DRB1', 'DQB1', 'DPB1'], fontsize=13) \n",
    "    plt.title('HWE p-values (mean out of\\n1000 runs) on 6 HLA loci', fontsize=15)       \n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     fig.set_dpi(300)    \n",
    "    \n",
    "#     if log10:\n",
    "#         plt.savefig(\"HWE p-values log transformation.png\")   \n",
    "#     else:\n",
    "#         plt.savefig(\"HWE p-values.png\")   \n",
    "       \n",
    "    plt.show()\n",
    "\n",
    "# Arlequin_HWE_pvalues(Crete_HW)\n",
    "Arlequin_HWE_pvalues(Crete_HW, log10=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b93c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arlequin_LD_pvalues(arlequin_DKMS,log10=None):\n",
    "    \n",
    "    if log10:\n",
    "        \n",
    "        # We are adding 0.0001 on 0.0 p-values, because log tranformation is not posssible\n",
    "        arlequin_DKMS = [-np.log10(x) for x in [0.0001 if x==0 else x for x in arlequin_DKMS]]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plt.scatter(list(range(1,76,5)), arlequin_DKMS, marker='*', color = 'blue',label='1835 Cretans',s=35)\n",
    "    \n",
    "    if log10:\n",
    "        plt.plot([0.8, 73.2],[-np.log10(0.05/15), -np.log10(0.05/15)], color ='red', label='a = -log10(0.05/15)')\n",
    "        plt.ylabel('-log10 transformed p-values', fontsize = 12)\n",
    "        ax.legend(loc='lower left')\n",
    "    else:\n",
    "        plt.plot([0.8, 73.2],[0.05/15, 0.05/15], color ='red', label='a = 0.05/15')\n",
    "    ### Corrected threshold: a / (number of loci pairs) where a == 0.05 and (number of loci pairs) == 15\n",
    "        plt.ylabel('p-values', fontsize = 15)    \n",
    "        ax.legend(loc='upper left')\n",
    "    \n",
    "    \n",
    "    plt.xticks(list(range(1,76,5)), ['A-B','A-C','B-C','A-DRB1','B-DRB1','C-DRB1','A-DQB1','B-DQB1','C-DQB1','DRB1-DQB1','A-DPB1','B-DPB1','C-DPB1','DRB1-DPB1','DQB1-DPB1'], fontsize=10, rotation=-90)\n",
    "    plt.title(\"Comparison of LD p-values per loci pair\", fontsize=15)       \n",
    "    \n",
    "#     fig.tight_layout()    \n",
    "#     fig.set_dpi(300)\n",
    "    \n",
    "#     if log10:\n",
    "#         plt.savefig(\"LD p-values log transformation.png\")\n",
    "#     else:\n",
    "#         plt.savefig(\"LD p-values.png\") \n",
    "       \n",
    "    plt.show()\n",
    "\n",
    "arlequin_DKMS_LD = obtain_pvalue_from_Arlequin_xml(f'{DKMS_LD_path}Crete_75_Arlequin_LD_all.xml', 'LD')    \n",
    "\n",
    "# Arlequin_LD_pvalues(arlequin_DKMS_LD[0],log10=None)\n",
    "Arlequin_LD_pvalues(arlequin_DKMS_LD[0],log10=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae98f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Arlequin 1000 times and get the mean of HWE p-values of all Prefectures \n",
    "\n",
    "a = '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/HW/'\n",
    "b = '../../../../arlecore_linux/arlecore3522_64bit HWequil.ars merged.arp'\n",
    "c = '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/HW/merged.res/'\n",
    "d = 'mv merged.xml merged_HW_6.xml'\n",
    "e = '/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/HW/merged.res/merged_HW_6.xml'\n",
    "\n",
    "def run_Arlequin_HWE_Prefectures(runs):\n",
    "    \n",
    "    pvals_Ch = []\n",
    "    pvals_Ret = []\n",
    "    pvals_Her = []\n",
    "    pvals_Las = []\n",
    "    \n",
    "    for run in range(runs):\n",
    "        print(run)\n",
    "        os.chdir(a)\n",
    "        os.system(b)\n",
    "        os.chdir(c)\n",
    "        os.system(d)\n",
    "\n",
    "        tmp_pvals = obtain_pvalue_from_Arlequin_xml(e, 'HW')\n",
    "\n",
    "        pvals_Ch.append(tmp_pvals[0])\n",
    "        pvals_Ret.append(tmp_pvals[1])\n",
    "        pvals_Her.append(tmp_pvals[2])\n",
    "        pvals_Las.append(tmp_pvals[3])\n",
    "    \n",
    "    os.chdir('/home/manos/Desktop/Manos/MSc-Bioinformatics/Thesis/scripts/Cretan_project/')\n",
    "    \n",
    "    return pvals_Ch, pvals_Ret, pvals_Her, pvals_Las\n",
    "\n",
    "pvals_Ch, pvals_Ret, pvals_Her, pvals_Las = run_Arlequin_HWE_Prefectures(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14dcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HWE AND LD COMPARISON PER PREFECTURE\n",
    "\n",
    "def prefectures_HWE_LD_pvalues(pvals, analysis, log10=None):\n",
    "    \n",
    "    if analysis not in ('HW', 'LD'):\n",
    "        raise Exception('analysis can only be HW or LD.')\n",
    "       \n",
    "    if log10:\n",
    "    \n",
    "        # We are adding 0.0001 on 0.0 p-values, because log tranformation is not posssible        \n",
    "        pvals = [-np.log10(z) for z in [[0.0001 if y==0 else y for y in x] for x in pvals]]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plt.scatter(list(range(1,len(pvals[0])+1)), pvals[0], marker='o',color='blue',label='Chania (455)',s=35,alpha=0.5)\n",
    "    plt.scatter(list(range(1,len(pvals[1])+1)), pvals[1], marker='*',color='magenta',label='Rethymno (280)',s=35,alpha=0.5)\n",
    "    plt.scatter(list(range(1,len(pvals[2])+1)), pvals[2], marker='>',color='green',label='Heraklion (678)',s=35,alpha=0.5)\n",
    "    plt.scatter(list(range(1,len(pvals[3])+1)), pvals[3], marker='s',color='orange',label='Lasithi (331)',s=35,alpha=0.5)\n",
    "    \n",
    "    if log10:\n",
    "        \n",
    "        if analysis == 'HW':\n",
    "            plt.plot([0.8, len(pvals[0])+0.2],[-np.log10(0.05/6), -np.log10(0.05/6)], color ='red', label='a = -log10(0.05/6)')\n",
    "        elif analysis == 'LD':\n",
    "            plt.plot([0.8, len(pvals[0])+0.2],[-np.log10(0.05/15), -np.log10(0.05/15)], color ='red', label='a = -log10(0.05/15)')\n",
    "    \n",
    "        plt.ylabel('-log10 transformed p-values', fontsize = 10)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if analysis == 'HW':\n",
    "            plt.plot([0.8, len(pvals[0])+0.2],[0.05/6, 0.05/6], color ='red', label='a = 0.05/6')\n",
    "        elif analysis == 'LD':\n",
    "            plt.plot([0.8, len(pvals[0])+0.2],[0.05/15, 0.05/15], color ='red', label='a = 0.05/15')\n",
    "    ### Corrected threshold: a / (number of genetic loci/pairs) where a == 0.05 and (number of genetic loci) == 6/15\n",
    "        plt.ylabel('p-values', fontsize = 15)    \n",
    "        \n",
    "    ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')    \n",
    "    \n",
    "    if analysis =='HW':\n",
    "        plt.xticks(list(range(1,len(pvals[0])+1)), ['A', 'B', 'C', 'DRB1', 'DQB1', 'DPB1'], fontsize=13) \n",
    "        plt.title('HWE p-values (mean out of 1000 runs)\\non 6 HLA loci per Prefecture', fontsize=15)    \n",
    "    elif analysis == 'LD':\n",
    "        plt.xticks(list(range(1,len(pvals[0])+1)), ['A-B','A-C','B-C','A-DRB1','B-DRB1','C-DRB1','A-DQB1','B-DQB1','C-DQB1','DRB1-DQB1','A-DPB1','B-DPB1','C-DPB1','DRB1-DPB1','DQB1-DPB1'], fontsize=10, rotation=-90)\n",
    "        plt.title(\"LD p-values per loci pair\\non 6 HLA loci per Prefecture\", fontsize=15)\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     fig.set_dpi(300)    \n",
    "    \n",
    "#     if log10:\n",
    "        \n",
    "#         if analysis == 'HW':\n",
    "#             plt.savefig('Prefectures_Analysis/Prefecture HWE p-values log transformation.png')\n",
    "#         elif analysis == 'LD':\n",
    "#             plt.savefig('Prefectures_Analysis/Prefecture LD p-values log transformation.png')\n",
    "#     else:\n",
    "        \n",
    "#         if analysis == 'HW':\n",
    "#             plt.savefig('Prefectures_Analysis/Prefecture HWE p-values.png')   \n",
    "#         elif analysis == 'LD':\n",
    "#             plt.savefig('Prefectures_Analysis/Prefecture LD p-values.png')\n",
    "       \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8045f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Ch_A, ci1_Ch_A, ci2_Ch_A = mean_confidence_interval([x[0] for x in pvals_Ch], confidence=0.95)\n",
    "m_Ch_B, ci1_Ch_B, ci2_Ch_B = mean_confidence_interval([x[1] for x in pvals_Ch], confidence=0.95)\n",
    "m_Ch_C, ci1_Ch_C, ci2_Ch_C = mean_confidence_interval([x[2] for x in pvals_Ch], confidence=0.95)\n",
    "m_Ch_DRB1, ci1_Ch_DRB1, ci2_Ch_DRB1 = mean_confidence_interval([x[3] for x in pvals_Ch], confidence=0.95)\n",
    "m_Ch_DQB1, ci1_Ch_DQB1, ci2_Ch_DQB1 = mean_confidence_interval([x[4] for x in pvals_Ch], confidence=0.95)\n",
    "m_Ch_DPB1, ci1_Ch_DPB1, ci2_Ch_DPB1 = mean_confidence_interval([x[5] for x in pvals_Ch], confidence=0.95)\n",
    "\n",
    "Ch_HW = [m_Ch_A,m_Ch_B,m_Ch_C,m_Ch_DRB1,m_Ch_DQB1,m_Ch_DPB1]\n",
    "\n",
    "m_Ret_A, ci1_Ret_A, ci2_Ret_A = mean_confidence_interval([x[0] for x in pvals_Ret], confidence=0.95)\n",
    "m_Ret_B, ci1_Ret_B, ci2_Ret_B = mean_confidence_interval([x[1] for x in pvals_Ret], confidence=0.95)\n",
    "m_Ret_C, ci1_Ret_C, ci2_Ret_C = mean_confidence_interval([x[2] for x in pvals_Ret], confidence=0.95)\n",
    "m_Ret_DRB1, ci1_Ret_DRB1, ci2_Ret_DRB1 = mean_confidence_interval([x[3] for x in pvals_Ret], confidence=0.95)\n",
    "m_Ret_DQB1, ci1_Ret_DQB1, ci2_Ret_DQB1 = mean_confidence_interval([x[4] for x in pvals_Ret], confidence=0.95)\n",
    "m_Ret_DPB1, ci1_Ret_DPB1, ci2_Ret_DPB1 = mean_confidence_interval([x[5] for x in pvals_Ret], confidence=0.95)\n",
    "\n",
    "Ret_HW = [m_Ret_A,m_Ret_B,m_Ret_C,m_Ret_DRB1,m_Ret_DQB1,m_Ret_DPB1]\n",
    "\n",
    "m_Her_A, ci1_Her_A, ci2_Her_A = mean_confidence_interval([x[0] for x in pvals_Her], confidence=0.95)\n",
    "m_Her_B, ci1_Her_B, ci2_Her_B = mean_confidence_interval([x[1] for x in pvals_Her], confidence=0.95)\n",
    "m_Her_C, ci1_Her_C, ci2_Her_C = mean_confidence_interval([x[2] for x in pvals_Her], confidence=0.95)\n",
    "m_Her_DRB1, ci1_Her_DRB1, ci2_Her_DRB1 = mean_confidence_interval([x[3] for x in pvals_Her], confidence=0.95)\n",
    "m_Her_DQB1, ci1_Her_DQB1, ci2_Her_DQB1 = mean_confidence_interval([x[4] for x in pvals_Her], confidence=0.95)\n",
    "m_Her_DPB1, ci1_Her_DPB1, ci2_Her_DPB1 = mean_confidence_interval([x[5] for x in pvals_Her], confidence=0.95)\n",
    "\n",
    "Her_HW = [m_Her_A,m_Her_B,m_Her_C,m_Her_DRB1,m_Her_DQB1,m_Her_DPB1]\n",
    "\n",
    "m_Las_A, ci1_Las_A, ci2_Las_A = mean_confidence_interval([x[0] for x in pvals_Las], confidence=0.95)\n",
    "m_Las_B, ci1_Las_B, ci2_Las_B = mean_confidence_interval([x[1] for x in pvals_Las], confidence=0.95)\n",
    "m_Las_C, ci1_Las_C, ci2_Las_C = mean_confidence_interval([x[2] for x in pvals_Las], confidence=0.95)\n",
    "m_Las_DRB1, ci1_Las_DRB1, ci2_Las_DRB1 = mean_confidence_interval([x[3] for x in pvals_Las], confidence=0.95)\n",
    "m_Las_DQB1, ci1_Las_DQB1, ci2_Las_DQB1 = mean_confidence_interval([x[4] for x in pvals_Las], confidence=0.95)\n",
    "m_Las_DPB1, ci1_Las_DPB1, ci2_Las_DPB1 = mean_confidence_interval([x[5] for x in pvals_Las], confidence=0.95)\n",
    "\n",
    "Las_HW = [m_Las_A,m_Las_B,m_Las_C,m_Las_DRB1,m_Las_DQB1,m_Las_DPB1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214020f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefectures_HW = obtain_pvalue_from_Arlequin_xml(f'/home/manos/Programs/Arlequin/cretan_HLA/prefectures/new_analysis/HW/merged.res/merged_HW_6.xml', 'HW')\n",
    "\n",
    "prefectures_HW = [Ch_HW, Ret_HW, Her_HW, Las_HW]\n",
    "# prefectures_HWE_LD_pvalues(prefectures_HW, analysis='HW')\n",
    "prefectures_HWE_LD_pvalues(prefectures_HW, analysis='HW', log10=True)\n",
    "\n",
    "#### DOES NOT RUN BECAUSE OF A NUMERIC ERROR PRINTED ON HERAKLION ARLEQUIN XML OUTPUT\n",
    "#### SO I SAVED THE P-VALUES WITH THE COMMAND ON TERMINAL BELOW:\n",
    "#### grep '(P = ' all_prefectures_LD_6.xml |gawk -F'P = ' '{print $2}'| gawk -F',' '{print $1}' > prefectures_LD_pvals.txt \n",
    "\n",
    "# prefectures_LD = obtain_pvalue_from_Arlequin_xml(f'/home/manos/Programs/Arlequin/cretan_HLA/prefectures/1744/LD/merged.res/merged_LD_6.xml', 'LD')\n",
    "\n",
    "ch_LD = [1.00000, 0.00000, 0.00000, 0.44722, 0.00000, 0.00000, 0.00020, 0.00000, 0.00000, 0.00000, 1.00000, 1.00000, 0.99971, 0.65537, 0.00050]\n",
    "ret_LD = [1.00000, 0.86585, 0.00000, 0.97357, 0.29853, 0.87768, 0.00092, 0.00106, 0.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 0.99983]\n",
    "her_LD = [0.08014, 0.00000, 0.00000, 0.00371, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 1.00000, 1.00000, 1.00000, 0.99482, 0.12632]\n",
    "las_LD = [1.00000, 0.71459, 0.00000, 1.00000, 0.94716, 0.03956, 0.99814, 0.00000, 0.00001, 0.00000, 1.00000, 1.00000, 1.00000, 0.99865, 0.38261]\n",
    "\n",
    "prefectures_LD = [ch_LD, ret_LD, her_LD, las_LD]\n",
    "\n",
    "# prefectures_HWE_LD_pvalues(prefectures_LD, analysis='LD')\n",
    "prefectures_HWE_LD_pvalues(prefectures_LD, analysis='LD', log10=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeea16b",
   "metadata": {},
   "source": [
    "## PYPOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a689cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pypop_input(txt_file):\n",
    "    \n",
    "    '''\n",
    "    This function converts Hapl-o-Mat input to PyPop input for HLA loci\n",
    "    The Hapl-o-Mat input should contain HLA genotypes of the HLA genes\n",
    "    -A, -B, -C, -DRB1, -DQB1 and -DPB1 in this order only.\n",
    "    '''\n",
    "    \n",
    "    with open(txt_file, 'r') as f:\n",
    "        f = f.readlines()\n",
    "        \n",
    "    f = [x.replace(':','').strip('\\n').split('\\t')[1:] for x in f][1:]\n",
    "    new_header = ['a_1', 'a_2', 'b_1', 'b_2', 'c_1', 'c_2', 'drb1_1', 'drb1_2', 'dqb1_1', 'dqb1_2', 'dpb1_1', 'dpb1_2']\n",
    "    final = [new_header]+f\n",
    "    \n",
    "    tmp = f'/home/manos/Programs/PyPopLinux-0.7.0/HLA/{n_Cretans}/'+txt_file.split('.')[0]+'.pop'\n",
    "    \n",
    "    if os.path.exists(tmp):\n",
    "        os.remove(tmp)\n",
    "    \n",
    "    with open(tmp,'w') as f:\n",
    "        wr = csv.writer(f, delimiter='\\t')\n",
    "        wr.writerows(final)\n",
    "\n",
    "# pypop_input('Crete_75.txt')\n",
    "# pypop_input('Chania_75.txt')\n",
    "# pypop_input('Rethymno_75.txt')\n",
    "# pypop_input('Heraklion_75.txt')\n",
    "# pypop_input('Lasithi_75.txt')\n",
    "# pypop_input('Mylopotamos_all.txt')\n",
    "# pypop_input('Rest_Rethymno_all.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54512dea",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be021310",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In order to compare the allele frequencies of the Cretan population with the DKMS minorities we must\n",
    "### group the alleles with g resolution as the DKMS did. We will estimate first the haplotype frequencies \n",
    "### with the Hapl-o-Mat software, because it can perform the g grouping and then, from the haplotype\n",
    "### frequencies we will calculate the grouped allele frequencies and compare them with the DKMS minorities'.\n",
    "### Arlequin cannot perform the grouping, so that is why it is not a suitable program for this task, although\n",
    "### it does not drop the genotypes with at least one missing value. If we do not drop these lines, the \n",
    "### estimated allele frequency would be closer to the real frequency of the sample.\n",
    "\n",
    "### After we run the Hapl-o-Mat with the g grouping without missing data we calculate the allele frequencies\n",
    "\n",
    "def af_estimation_from_HaploMat_g_group(hfs_dat, hla_gene, num_of_people, alleles=None, counts=None):\n",
    "    \n",
    "    '''\n",
    "    !!!README!!!\n",
    "    \n",
    "    This function calculates the allele frequency of the HLA genes A, B, C, DRB1, DQB1 and DPB1 \n",
    "    if the haplotypes have them. \n",
    "    \n",
    "    Hapl-o-Mat orders the genes in the haplotypes alphabetically.\n",
    "    \n",
    "    The haplotypes with 4 genes should have the HLA genes below in this order only:\n",
    "    A~B~C~DRB1\n",
    "    \n",
    "    The haplotypes with 5 genes should have the HLA genes below in this order only:\n",
    "    A~B~C~DQB1~DRB1\n",
    "    \n",
    "    The haplotypes with 6 genes should have the HLA genes below in this order only:\n",
    "    A~B~C~DPB1~DQB1~DRB1\n",
    "    \n",
    "    Other combinations of the HLA genes can not be used as input.    \n",
    "    \n",
    "    This function returns the estimated allele frequencies/counts and alleles of the sample from Hapl-o-Mat.\n",
    "    '''\n",
    "    \n",
    "    if hla_gene not in ('A', 'B', 'C', 'DRB1', 'DQB1', 'DPB1'):\n",
    "        raise Exception(\"The hla_gene can only be 'A', 'B', 'C', 'DRB1', 'DQB1' or 'DPB1'\")\n",
    "        \n",
    "    if counts and alleles:\n",
    "        raise Exception('Only 1 output can come from this function.')\n",
    "    \n",
    "    with open(hfs_dat, 'r') as f:\n",
    "        f = f.readlines()\n",
    "        \n",
    "    f = [x.strip('\\n').split('\\t') for x in f]\n",
    "    allele_freq = [(x[0].split('~'), float(x[1])) for x in f]\n",
    "    allele_freq = [([y.strip('g') for y in x[0]],x[1]) for x in allele_freq]\n",
    "    \n",
    "    if hla_gene == 'A':\n",
    "        n = 0        \n",
    "    elif hla_gene == 'B':\n",
    "        n = 1        \n",
    "    elif hla_gene == 'C':\n",
    "        n = 2        \n",
    "    \n",
    "    elif hla_gene == 'DRB1': # Hapl-o-Mat orders the genes in the haplotypes alphabetically.\n",
    "        if len(allele_freq[0][0]) == 4:     \n",
    "            n = 3\n",
    "        elif len(allele_freq[0][0]) == 5:     \n",
    "            n = 4    \n",
    "        elif len(allele_freq[0][0]) == 6:\n",
    "            n = 5\n",
    "        else:\n",
    "            raise Exception('The haplotypes should have 4, 5 or 6 genes in a specific order. Read the documentation.')\n",
    "    \n",
    "    elif hla_gene == 'DQB1':\n",
    "        if len(allele_freq[0][0]) == 4:     \n",
    "            raise Exception('DQB1 should not be in a haplotype with only 4 genes. Read the documentation.')\n",
    "        elif len(allele_freq[0][0]) == 5:     \n",
    "            n = 3    \n",
    "        elif len(allele_freq[0][0]) == 6:\n",
    "            n = 4\n",
    "        else:\n",
    "            raise Exception('The haplotypes should have 4, 5 or 6 genes in a specific order. Read the documentation.')                 \n",
    "    \n",
    "    elif hla_gene == 'DPB1':\n",
    "        if len(allele_freq[0][0]) == 4:     \n",
    "            raise Exception('DPB1 should not be in a haplotype with only 4 genes. Read the documentation.')\n",
    "        elif len(allele_freq[0][0]) == 5:     \n",
    "            raise Exception('DPB1 should not be in a haplotype with only 5 genes. Read the documentation.')    \n",
    "        elif len(allele_freq[0][0]) == 6:\n",
    "            n = 3\n",
    "        else:\n",
    "            raise Exception('The haplotypes should have 4, 5 or 6 genes in a specific order. Read the documentation.')\n",
    "    \n",
    "    HLA_gene = {el:0 for el in [x[0][n] for x in allele_freq]}\n",
    "    \n",
    "    for x in allele_freq:\n",
    "        HLA_gene[x[0][n]] += x[1]\n",
    "    \n",
    "    HLA_gene = {k:v for k, v in sorted(HLA_gene.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    if alleles:\n",
    "        return list(HLA_gene.keys())\n",
    "    \n",
    "    elif counts:        \n",
    "        return {k:round(v*num_of_people) for k,v in HLA_gene.items()} \n",
    "        # No need to multiply by 2, because of the 2 genotypes on MAC input\n",
    "    \n",
    "    else:\n",
    "        return HLA_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pref_dkms(chania, rethymno, heraklion, lasithi, aus, bos, cro, fra, ita, net, por, rom, spa, tur, uk, gre, chi, all_alleles=True, af_filter=None):\n",
    "    \n",
    "    ita = ita[ita['gene']!='DQB1']\n",
    "    tur = tur[tur['gene']!='DQB1']\n",
    "    \n",
    "    aus_info = dict(zip(aus['allele'].to_list(), aus['af'].to_list()))\n",
    "    bos_info = dict(zip(bos['allele'].to_list(), bos['af'].to_list()))\n",
    "    cro_info = dict(zip(cro['allele'].to_list(), cro['af'].to_list()))\n",
    "    fra_info = dict(zip(fra['allele'].to_list(), fra['af'].to_list()))\n",
    "    ita_info = dict(zip(ita['allele'].to_list(), ita['af'].to_list()))\n",
    "    net_info = dict(zip(net['allele'].to_list(), net['af'].to_list()))\n",
    "    por_info = dict(zip(por['allele'].to_list(), por['af'].to_list()))\n",
    "    rom_info = dict(zip(rom['allele'].to_list(), rom['af'].to_list()))\n",
    "    spa_info = dict(zip(spa['allele'].to_list(), spa['af'].to_list()))\n",
    "    tur_info = dict(zip(tur['allele'].to_list(), tur['af'].to_list()))\n",
    "    uk_info = dict(zip(uk['allele'].to_list(), uk['af'].to_list()))\n",
    "    gre_info = dict(zip(gre['allele'].to_list(), gre['af'].to_list()))\n",
    "    \n",
    "    chania_alleles = list(chania.keys())\n",
    "    rethymno_alleles = list(rethymno.keys())\n",
    "    heraklion_alleles = list(heraklion.keys())\n",
    "    lasithi_alleles = list(lasithi.keys())\n",
    "    aus_alleles = aus['allele'].to_list()\n",
    "    bos_alleles = bos['allele'].to_list()\n",
    "    cro_alleles = cro['allele'].to_list()\n",
    "    fra_alleles = fra['allele'].to_list()\n",
    "    ita_alleles = ita['allele'].to_list()\n",
    "    net_alleles = net['allele'].to_list()\n",
    "    por_alleles = por['allele'].to_list()\n",
    "    rom_alleles = rom['allele'].to_list()\n",
    "    spa_alleles = spa['allele'].to_list()\n",
    "    tur_alleles = tur['allele'].to_list()\n",
    "    uk_alleles = uk['allele'].to_list()\n",
    "    gre_alleles = gre['allele'].to_list() \n",
    "    \n",
    "    if not chi.empty:\n",
    "        chi_info = dict(zip(chi['allele'].to_list(), chi['af'].to_list()))\n",
    "        chi_alleles = chi['allele'].to_list()\n",
    "        d = [chania_alleles, rethymno_alleles, heraklion_alleles, lasithi_alleles, aus_alleles, bos_alleles, cro_alleles, fra_alleles, ita_alleles, net_alleles, por_alleles, rom_alleles, spa_alleles, tur_alleles, uk_alleles, gre_alleles, chi_alleles]\n",
    "    else:\n",
    "        d = [chania_alleles, rethymno_alleles, heraklion_alleles, lasithi_alleles, aus_alleles, bos_alleles, cro_alleles, fra_alleles, ita_alleles, net_alleles, por_alleles, rom_alleles, spa_alleles, tur_alleles, uk_alleles, gre_alleles]\n",
    "    \n",
    "    if all_alleles: \n",
    "        final_alleles = list(sorted(set(list(itertools.chain.from_iterable(d)))))\n",
    "    else:\n",
    "        final_alleles = list(sorted(set(d[0]).intersection(*d)))\n",
    "        \n",
    "    total_alleles = len(final_alleles)\n",
    "    \n",
    "    dkms_pool = []\n",
    "    dkms_pool.append(chania);dkms_pool.append(rethymno);dkms_pool.append(heraklion);dkms_pool.append(lasithi)\n",
    "    dkms_pool.append(aus_info);dkms_pool.append(bos_info);dkms_pool.append(cro_info);dkms_pool.append(fra_info)\n",
    "    dkms_pool.append(ita_info);dkms_pool.append(net_info);dkms_pool.append(por_info);dkms_pool.append(rom_info)\n",
    "    dkms_pool.append(spa_info);dkms_pool.append(tur_info);dkms_pool.append(uk_info);dkms_pool.append(gre_info)\n",
    "    \n",
    "    markers = {'Chania':'o', 'Rethymno':'o', 'Heraklion':'o', 'Lasithi':'o', 'Austrians':'v', \n",
    "               'Bosnians':'>', 'Croatians':'<', 'French':'1', 'Italians':'2', 'Netherlands':'3', \n",
    "               'Portuguese':'s', 'Romanians':'D', 'Spaniards':'|', 'Turkish':'*', 'United Kingdom':'_', \n",
    "               'Greeks':'+'}\n",
    "    \n",
    "    colors = {'Chania':'olive', 'Rethymno':'mediumseagreen', 'Heraklion':'orangered', 'Lasithi':'goldenrod', \n",
    "              'Austrians':'blue', 'Bosnians':'green', 'Croatians':'magenta', 'French':'crimson', \n",
    "              'Italians':'orange', 'Netherlands':'aqua' , 'Portuguese':'coral', 'Romanians':'black', \n",
    "              'Spaniards':'brown', 'Turkish':'coral', 'United Kingdom':'lime', 'Greeks':'blueviolet'}\n",
    "            \n",
    "    populations = ['Chania', 'Rethymno', 'Heraklion', 'Lasithi', 'Austrians', 'Bosnians', 'Croatians', 'French', 'Italians', 'Netherlands', 'Portuguese', 'Romanians', 'Spaniards', 'Turkish', 'United Kingdom', 'Greeks']\n",
    "\n",
    "    if not chi.empty:  \n",
    "        dkms_pool.append(chi_info)\n",
    "        table_tmp = np.zeros([17, total_alleles])\n",
    "        populations.append('Chinese')\n",
    "        markers['Chinese']='x'\n",
    "        colors['Chinese']='navy'\n",
    "    else:\n",
    "        table_tmp = np.zeros([16, total_alleles])\n",
    "    \n",
    "    for x in range(len(dkms_pool)):\n",
    "        for y in range(total_alleles):\n",
    "            if final_alleles[y] in dkms_pool[x].keys():\n",
    "                table_tmp[x][y] += dkms_pool[x][final_alleles[y]]\n",
    "                \n",
    "    df1 = pd.DataFrame(data=table_tmp, index=list(range(1, table_tmp.shape[0]+1)), columns=final_alleles)     \n",
    "\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit(df1.values)\n",
    "    pr_data = pca.fit_transform(df1.values)\n",
    "    pc1, pc2 = pca.explained_variance_ratio_\n",
    "\n",
    "    df = pd.DataFrame(dict(x=pr_data[:,0], y=pr_data[:,1], label=populations))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped = df.groupby('label')\n",
    "    \n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key], marker=markers[key], s=20)\n",
    "\n",
    "    plt.xlabel(f'PC1 (variance explained: {round(pc1*100,2)}%)', fontsize = 14)\n",
    "    plt.ylabel(f'PC2 (variance explained: {round(pc2*100,2)}%)', fontsize = 12)\n",
    "    plt.gca().invert_xaxis() # So it can be comparable optically with the previous PCA plots with the whole Crete\n",
    "    \n",
    "#     if not chi.empty: \n",
    "#         if all_alleles:             \n",
    "#             if af_filter:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and DKMS\\n(with Chinese), ALL alleles, FILTERED\", fontsize=13)                \n",
    "#             else:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and DKMS\\n(with Chinese), ALL alleles\", fontsize=13)\n",
    "                \n",
    "#         else:            \n",
    "#             if af_filter:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and DKMS\\n(with Chinese), COMMON alleles, FILTERED\", fontsize=12)    \n",
    "#             else:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and DKMS\\n(with Chinese), COMMON alleles\", fontsize=13)       \n",
    "#     else:\n",
    "#         if all_alleles:             \n",
    "#             if af_filter:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and\\nDKMS, ALL alleles, FILTERED\", fontsize=15)           \n",
    "#             else:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and\\nDKMS, ALL alleles\", fontsize=15)\n",
    "                \n",
    "#         else:            \n",
    "#             if af_filter:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and\\nDKMS, COMMON alleles, FILTERED\", fontsize=14)                \n",
    "#             else:\n",
    "#                 plt.title(\"PCA on Cretan Prefectures and\\nDKMS, COMMON alleles\", fontsize=15)\n",
    "    \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "#     fig.set_dpi(300)\n",
    "#     fig.tight_layout()\n",
    "    \n",
    "#     if not chi.empty: \n",
    "#         if all_alleles:             \n",
    "#             if af_filter:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS with Chinese ALL alleles FILTERED.png\")                \n",
    "#             else:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS with Chinese ALL alleles.png\")\n",
    "                \n",
    "#         else:            \n",
    "#             if af_filter:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS with Chinese COMMON alleles FILTERED.png\")                \n",
    "#             else:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS with Chinese COMMON alleles.png\")            \n",
    "#     else:\n",
    "#         if all_alleles:             \n",
    "#             if af_filter:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS ALL alleles FILTERED.png\")                \n",
    "#             else:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS ALL alleles.png\")\n",
    "                \n",
    "#         else:            \n",
    "#             if af_filter:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS COMMON alleles FILTERED.png\")                \n",
    "#             else:\n",
    "#                 plt.savefig(\"Prefectures_Analysis/PCA on Cretan Prefectures and DKMS COMMON alleles.png\")\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#The hfs.dat file is a Haplomat output\n",
    "\n",
    "ch_4g_path = '/home/manos/Programs/Hapl-o-Mat/test/Chania/4genes_g/hfs.dat'   \n",
    "ret_4g_path = '/home/manos/Programs/Hapl-o-Mat/test/Rethymno/4genes_g/hfs.dat'\n",
    "her_4g_path = '/home/manos/Programs/Hapl-o-Mat/test/Heraklion/4genes_g/hfs.dat'\n",
    "las_4g_path = '/home/manos/Programs/Hapl-o-Mat/test/Lasithi/4genes_g/hfs.dat'\n",
    "\n",
    "chania_Ag = af_estimation_from_HaploMat_g_group(ch_4g_path, 'A', 455)     \n",
    "chania_Bg = af_estimation_from_HaploMat_g_group(ch_4g_path, 'B', 455)\n",
    "chania_Cg = af_estimation_from_HaploMat_g_group(ch_4g_path, 'C', 455)\n",
    "chania_DRB1g = af_estimation_from_HaploMat_g_group(ch_4g_path, 'DRB1', 455)\n",
    "\n",
    "rethymno_Ag = af_estimation_from_HaploMat_g_group(ret_4g_path, 'A', 280)     \n",
    "rethymno_Bg = af_estimation_from_HaploMat_g_group(ret_4g_path, 'B', 280)\n",
    "rethymno_Cg = af_estimation_from_HaploMat_g_group(ret_4g_path, 'C', 280)\n",
    "rethymno_DRB1g = af_estimation_from_HaploMat_g_group(ret_4g_path, 'DRB1', 280)\n",
    "\n",
    "heraklion_Ag = af_estimation_from_HaploMat_g_group(her_4g_path, 'A', 678)     \n",
    "heraklion_Bg = af_estimation_from_HaploMat_g_group(her_4g_path, 'B', 678)\n",
    "heraklion_Cg = af_estimation_from_HaploMat_g_group(her_4g_path, 'C', 678)\n",
    "heraklion_DRB1g = af_estimation_from_HaploMat_g_group(her_4g_path, 'DRB1', 678)\n",
    "\n",
    "lasithi_Ag = af_estimation_from_HaploMat_g_group(las_4g_path, 'A', 331)     \n",
    "lasithi_Bg = af_estimation_from_HaploMat_g_group(las_4g_path, 'B', 331)\n",
    "lasithi_Cg = af_estimation_from_HaploMat_g_group(las_4g_path, 'C', 331)\n",
    "lasithi_DRB1g = af_estimation_from_HaploMat_g_group(las_4g_path, 'DRB1', 331)\n",
    "\n",
    "chania_4g = {**chania_Ag, **chania_Bg, **chania_Cg, **chania_DRB1g}\n",
    "rethymno_4g = {**rethymno_Ag, **rethymno_Bg, **rethymno_Cg, **rethymno_DRB1g}\n",
    "heraklion_4g = {**heraklion_Ag, **heraklion_Bg, **heraklion_Cg, **heraklion_DRB1g}\n",
    "lasithi_4g = {**lasithi_Ag, **lasithi_Bg, **lasithi_Cg, **lasithi_DRB1g}\n",
    "\n",
    "chania_4gb = {k:v for k,v in chania_4g.items() if v > round(1/(2*455), 6)}\n",
    "rethymno_4gb = {k:v for k,v in rethymno_4g.items() if v > round(1/(2*280), 6)}\n",
    "heraklion_4gb = {k:v for k,v in heraklion_4g.items() if v > round(1/(2*678), 6)}\n",
    "lasithi_4gb = {k:v for k,v in lasithi_4g.items() if v > round(1/(2*331), 6)}\n",
    "\n",
    "# pca_pref_dkms(chania_4g, rethymno_4g, heraklion_4g, lasithi_4g, austrian_minority_in_Germany, bosnian_minority_in_Germany, croatian_minority_in_Germany, french_minority_in_Germany, italian_minority_in_Germany, netherlands_minority_in_Germany, portuguese_minority_in_Germany, romanian_minority_in_Germany, spanish_minority_in_Germany, turkish_minority_in_Germany, united_kingdom_minority_in_Germany, greek_minority_in_Germany, chinese_minority_in_Germany, all_alleles=True)\n",
    "# pca_pref_dkms(chania_4g, rethymno_4g, heraklion_4g, lasithi_4g, austrian_minority_in_Germany, bosnian_minority_in_Germany, croatian_minority_in_Germany, french_minority_in_Germany, italian_minority_in_Germany, netherlands_minority_in_Germany, portuguese_minority_in_Germany, romanian_minority_in_Germany, spanish_minority_in_Germany, turkish_minority_in_Germany, united_kingdom_minority_in_Germany, greek_minority_in_Germany, pd.DataFrame(), all_alleles=True)\n",
    "# pca_pref_dkms(chania_4gb, rethymno_4gb, heraklion_4gb, lasithi_4gb, austrian_minority_in_Germany2, bosnian_minority_in_Germany2, croatian_minority_in_Germany2, french_minority_in_Germany2, italian_minority_in_Germany2, netherlands_minority_in_Germany2, portuguese_minority_in_Germany2, romanian_minority_in_Germany2, spanish_minority_in_Germany2, turkish_minority_in_Germany2, united_kingdom_minority_in_Germany2, greek_minority_in_Germany2, chinese_minority_in_Germany2, all_alleles=True, af_filter=True)\n",
    "# pca_pref_dkms(chania_4gb, rethymno_4gb, heraklion_4gb, lasithi_4gb, austrian_minority_in_Germany2, bosnian_minority_in_Germany2, croatian_minority_in_Germany2, french_minority_in_Germany2, italian_minority_in_Germany2, netherlands_minority_in_Germany2, portuguese_minority_in_Germany2, romanian_minority_in_Germany2, spanish_minority_in_Germany2, turkish_minority_in_Germany2, united_kingdom_minority_in_Germany2, greek_minority_in_Germany2, pd.DataFrame(), all_alleles=True, af_filter=True)\n",
    "# pca_pref_dkms(chania_4g, rethymno_4g, heraklion_4g, lasithi_4g, austrian_minority_in_Germany, bosnian_minority_in_Germany, croatian_minority_in_Germany, french_minority_in_Germany, italian_minority_in_Germany, netherlands_minority_in_Germany, portuguese_minority_in_Germany, romanian_minority_in_Germany, spanish_minority_in_Germany, turkish_minority_in_Germany, united_kingdom_minority_in_Germany, greek_minority_in_Germany, chinese_minority_in_Germany, all_alleles=False)\n",
    "# pca_pref_dkms(chania_4g, rethymno_4g, heraklion_4g, lasithi_4g, austrian_minority_in_Germany, bosnian_minority_in_Germany, croatian_minority_in_Germany, french_minority_in_Germany, italian_minority_in_Germany, netherlands_minority_in_Germany, portuguese_minority_in_Germany, romanian_minority_in_Germany, spanish_minority_in_Germany, turkish_minority_in_Germany, united_kingdom_minority_in_Germany, greek_minority_in_Germany, pd.DataFrame(), all_alleles=False)\n",
    "# pca_pref_dkms(chania_4gb, rethymno_4gb, heraklion_4gb, lasithi_4gb, austrian_minority_in_Germany2, bosnian_minority_in_Germany2, croatian_minority_in_Germany2, french_minority_in_Germany2, italian_minority_in_Germany2, netherlands_minority_in_Germany2, portuguese_minority_in_Germany2, romanian_minority_in_Germany2, spanish_minority_in_Germany2, turkish_minority_in_Germany2, united_kingdom_minority_in_Germany2, greek_minority_in_Germany2, chinese_minority_in_Germany2, all_alleles=False, af_filter=True)\n",
    "pca_pref_dkms(chania_4gb, rethymno_4gb, heraklion_4gb, lasithi_4gb, austrian_minority_in_Germany2, bosnian_minority_in_Germany2, croatian_minority_in_Germany2, french_minority_in_Germany2, italian_minority_in_Germany2, netherlands_minority_in_Germany2, portuguese_minority_in_Germany2, romanian_minority_in_Germany2, spanish_minority_in_Germany2, turkish_minority_in_Germany2, united_kingdom_minority_in_Germany2, greek_minority_in_Germany2, pd.DataFrame(), all_alleles=False, af_filter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437436c",
   "metadata": {},
   "source": [
    "## clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr,aus,bos,cro,fre,gre,ita,net,por,rom,spa,tur,uni: Estimated Haplotypes for each country\n",
    "\n",
    "def calculate_distances(cr,aus,bos,cro,fre,gre,ita,net,por,rom,spa,tur,uni, euclidean=None, prevosti=None, chi=None):\n",
    "    \n",
    "    if sum([x for x in [euclidean,prevosti] if x])==0 or sum([x for x in [euclidean,prevosti] if x])==2:\n",
    "        raise Exception(\"Choose either Euclidean or Prevosti's distance.\")\n",
    "\n",
    "    if chi:\n",
    "        population_list = [cr,aus,bos,chi,cro,fre,gre,ita,net,por,rom,spa,tur,uni]\n",
    "        population_names = ['Crete', 'Austria', 'Bosnia-Erzegovina', 'China', 'Croatia', 'France', 'Greece', 'Italy', 'Netherlands' ,'Portugal', 'Romania', 'Spain', 'Turkey', 'United kingdom']\n",
    "                \n",
    "    else:\n",
    "        population_list = [cr,aus,bos,cro,fre,gre,ita,net,por,rom,spa,tur,uni]\n",
    "        population_names = ['Crete', 'Austria', 'Bosnia-Erzegovina', 'Croatia', 'France', 'Greece', 'Italy', 'Netherlands' ,'Portugal', 'Romania', 'Spain', 'Turkey', 'United kingdom']\n",
    "    \n",
    "    arr = np.zeros((len(population_names),len(population_names)))\n",
    "    \n",
    "    for x in range(len(population_list)):\n",
    "        for y in range(len(population_names)):\n",
    "            if population_list[x] != population_list[y]:\n",
    "                \n",
    "                all_haplotypes = list(set(list(population_list[x].keys())+list(population_list[y].keys())))\n",
    "                a = [population_list[x][z] if z in population_list[x].keys() else 0 for z in all_haplotypes]\n",
    "                b = [population_list[y][z] if z in population_list[y].keys() else 0 for z in all_haplotypes]                \n",
    " \n",
    "                if euclidean:\n",
    "                    arr[x][y] += np.linalg.norm(np.array(a)-np.array(b))\n",
    "                    \n",
    "                elif prevosti: # similar to Manhattan distance\n",
    "                    arr[x][y] += np.sum(np.abs(np.array(a)-np.array(b)))*0.5\n",
    "                \n",
    "    df = pd.DataFrame(data=arr, index=population_names, columns=population_names)            \n",
    "            \n",
    "    \n",
    "    return df\n",
    "\n",
    "euc_distances = calculate_distances(cr_hapl,austrian_hapl_freq,bosnian_hapl_freq,croatia_hapl_freq,french_hapl_freq,greek_hapl_freq,italian_hapl_freq,netherland_hapl_freq,portugal_hapl_freq,romanian_hapl_freq,spanish_hapl_freq,turkish_hapl_freq,united_kingdom_hapl_freq, euclidean=True, prevosti=None)\n",
    "prev_distances = calculate_distances(cr_hapl,austrian_hapl_freq,bosnian_hapl_freq,croatia_hapl_freq,french_hapl_freq,greek_hapl_freq,italian_hapl_freq,netherland_hapl_freq,portugal_hapl_freq,romanian_hapl_freq,spanish_hapl_freq,turkish_hapl_freq,united_kingdom_hapl_freq, euclidean=None, prevosti=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.clustermap(prev_distances)\n",
    "g = sns.clustermap(prev_distances, cmap='Greys_r')\n",
    "\n",
    "plt.tight_layout()\n",
    "# g.savefig(f\"Cluster Map {n_Cretans}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed20647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffd1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1b825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293c41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88f5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
